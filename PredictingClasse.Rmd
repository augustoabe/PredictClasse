---
title: "PredictingClasse"
author: "Augusto Abe"
date: "03/11/2020"
output:
  pdf_document: default
  html_document: default
---

Loading the data sets
```{r}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

Looking at variables with NAs.
```{r}
num_nas <- c()
num_rows <- nrow(training)
num_cols <- ncol(training)

for(i in 1:num_cols){
        nas <- is.na(training[,i])
        num_nas <- c(num_nas, length(nas[nas]))
}

as.numeric(levels(as.factor(num_nas)))/num_rows
```
Variables or do not have NA or 98% of your observations are NA so this variables with NAs will be excluded
```{r}
var_nas <- num_nas > 0
training <- training[,!var_nas]
```

Now we will do the same thing with empty values ("").
```{r}
num_empties <- c()
num_cols <- ncol(training)

for(i in 1:num_cols){
        empties <- training[,i] == ""
        num_empties <- c(num_empties, length(empties[empties]))
}

as.numeric(levels(as.factor(num_nas)))/num_rows
```
This is the same result as NA.
```{r}
var_empties <- num_empties > 0
training <- training[,!var_empties]
```


Now we will change the class of the variables or guarantee that they belong to the correct class and remove X column.
```{r}
training <- training[,-1]
training$user_name <- as.factor(training$user_name)
training$classe <- as.factor(training$classe)
training$cvtd_timestamp <- as.POSIXct(training$cvtd_timestamp, format = "%d/%m/%Y %H:%M")
training$new_window <- as.factor(training$new_window)

for(i in c(2, 3, 6:58 )){
        training[,i] <- as.numeric(training[,i])
}
```
Now our data set is cleaned.

As our variable to be predicted is categorical we try test three models: linear discriminant analysis, tree and random forest

Linear discriminant analysis:
```{r}
library(caret)
model_lda <- train(classe~., data = training, method = "lda",
               trControl = trainControl(method = "cv",
                                        number = 10))

print(model_lda)
```

Tree:
```{r}
model_tree <- train(classe~., data = training, method = "rpart",
               trControl = trainControl(method = "cv",
                                        number = 10))

print(model_tree)
```

Random Forest:
```{r}
model_rf <- train(classe~., data = training, method = "rf",
               trControl = trainControl(method = "cv",
                                        number = 10))

print(model_rf)
```
From the three model the random forest has the highest precision so this will be the final model.

Processing the test set.
```{r}
testing <- testing[,!var_nas]
testing <- testing[,!var_empties]
testing <- testing[,-1]
testing$user_name <- as.factor(testing$user_name)
testing$cvtd_timestamp <- as.POSIXct(testing$cvtd_timestamp, format = "%d/%m/%Y %H:%M")
testing$new_window <- as.factor(testing$new_window)

for(i in c(2, 3, 6:58 )){
        testing[,i] <- as.numeric(testing[,i])
}
```

Now we can predict in the test set.
```{r}
predict(model_rf, testing)
```